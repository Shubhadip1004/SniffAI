{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "p4bgrS2RUcJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "c4xU-vHX4OT5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxR2eKxn4Ks7",
        "outputId": "09b1fa69-2bd9-4e72-c073-344f3d2223a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/ayushmandatta1/deepdetect-2025\n",
            "License(s): apache-2.0\n",
            "Downloading deepdetect-2025.zip to /content\n",
            "100% 3.22G/3.23G [01:25<00:00, 189MB/s]\n",
            "100% 3.23G/3.23G [01:25<00:00, 40.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ayushmandatta1/deepdetect-2025"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/deepdetect-2025.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "WoTzwR7h4XXv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Removing Inconsistant Images"
      ],
      "metadata": {
        "id": "h6zrSZqiW4-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "def clean_directory(directory):\n",
        "    cleaned_files_count = 0\n",
        "    # Strictly enforce extensions required by TensorFlow's decode_image based on the error message\n",
        "    required_image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            filepath = os.path.join(root, file)\n",
        "            file_size = os.path.getsize(filepath)\n",
        "\n",
        "            # First, filter out zero-byte files as they are definitely problematic\n",
        "            if file_size == 0:\n",
        "                print(f\"Removing zero-byte file: {filepath}\")\n",
        "                os.remove(filepath)\n",
        "                cleaned_files_count += 1\n",
        "                continue\n",
        "\n",
        "            # Check if the file has one of the strictly required image extensions\n",
        "            if filepath.lower().endswith(required_image_extensions):\n",
        "                try:\n",
        "                    # Try to open it with PIL first for a quick check\n",
        "                    Image.open(filepath).close()\n",
        "\n",
        "                    # Then, try to decode it with TensorFlow to catch more subtle issues\n",
        "                    img_bytes = tf.io.read_file(filepath)\n",
        "                    _ = tf.io.decode_image(img_bytes, channels=3, expand_animations=False)\n",
        "\n",
        "                except Exception as e:\n",
        "                    # If either PIL or TensorFlow decoding fails, it's corrupted or problematic\n",
        "                    print(f\"Removing corrupted/undecodable image file: {filepath} - Error: {e}\")\n",
        "                    os.remove(filepath)\n",
        "                    cleaned_files_count += 1\n",
        "            else:\n",
        "                # If it doesn't have a required extension, remove it.\n",
        "                # This covers cases like WEBP/TIFF/PDF/etc. that TF's decoder might not support by default.\n",
        "                print(f\"Removing file with unsupported extension: {filepath}\")\n",
        "                os.remove(filepath)\n",
        "                cleaned_files_count += 1\n",
        "    return cleaned_files_count\n",
        "\n",
        "print(\"Cleaning train directory...\")\n",
        "cleaned_train_count = clean_directory('/content/ddata/train')\n",
        "print(f\"Removed {cleaned_train_count} problematic files from train directory.\")\n",
        "\n",
        "print(\"Cleaning test directory...\")\n",
        "cleaned_test_count = clean_directory('/content/ddata/test')\n",
        "print(f\"Removed {cleaned_test_count} problematic files from test directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLWskCaEJQhb",
        "outputId": "f8aeed2e-6cc8-4456-a1dd-7b8efa36df26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning train directory...\n",
            "Removed 0 problematic files from train directory.\n",
            "Cleaning test directory...\n",
            "Removed 0 problematic files from test directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Conv2D, GlobalAveragePooling2D, Flatten\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "n610dgGI5LXH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementing Image Batches & Normalizing\n"
      ],
      "metadata": {
        "id": "2_5U3-gAXDLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/ddata/train',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 128,\n",
        "    color_mode = 'rgb',\n",
        "    image_size = (240, 240)\n",
        ")\n",
        "\n",
        "test_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/ddata/test',\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size = 64,\n",
        "    color_mode = 'rgb',\n",
        "    image_size = (240, 240)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBUpEQoO5iSD",
        "outputId": "81b196c5-b856-42ee-c4b1-e9459fb3ff75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 90407 files belonging to 2 classes.\n",
            "Found 21776 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.efficientnet import preprocess_input\n",
        "def process(image, label):\n",
        "    image = preprocess_input(image)\n",
        "    return image,label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "test_ds = test_ds.map(process)"
      ],
      "metadata": {
        "id": "YPMFukngAm3D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Phase 1"
      ],
      "metadata": {
        "id": "6libdmQhUUkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import EfficientNetB1"
      ],
      "metadata": {
        "id": "JREj3fQKA2e5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    keras.layers.RandomFlip(\"horizontal\"),\n",
        "    keras.layers.RandomRotation(0.2),\n",
        "    keras.layers.RandomZoom(0.2),\n",
        "    keras.layers.RandomContrast(0.2)\n",
        "])"
      ],
      "metadata": {
        "id": "7_vTF4vu1Dus"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(240,240,3))\n",
        "\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)   # EfficientNet preprocessing\n",
        "\n",
        "base_model = EfficientNetB1(include_top=False, weights='imagenet')\n",
        "base_model.trainable = False    # IMPORTANT (Phase 1)\n",
        "\n",
        "x = base_model(x, training=False)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "yg4zrQ5X0XpU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "8a87MCHMJLRU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model.fit(train_ds, epochs=5, validation_data=test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hsw0dD_QZxl",
        "outputId": "778eae86-2629-4626-c70f-0201d8a432aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 526ms/step - accuracy: 0.6277 - loss: 0.8403 - val_accuracy: 0.6762 - val_loss: 0.6418\n",
            "Epoch 2/5\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 498ms/step - accuracy: 0.7247 - loss: 0.5839 - val_accuracy: 0.6985 - val_loss: 0.6089\n",
            "Epoch 3/5\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 497ms/step - accuracy: 0.7522 - loss: 0.5182 - val_accuracy: 0.7367 - val_loss: 0.5358\n",
            "Epoch 4/5\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 497ms/step - accuracy: 0.7747 - loss: 0.4793 - val_accuracy: 0.7319 - val_loss: 0.5451\n",
            "Epoch 5/5\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 497ms/step - accuracy: 0.7809 - loss: 0.4595 - val_accuracy: 0.7512 - val_loss: 0.5155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2nd Phase"
      ],
      "metadata": {
        "id": "fPlE20rx2gO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "h_n9IC7AfiU7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "5s4BG9-F2n-K"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxVxPMaA2tZK",
        "outputId": "26f6461b-6279-4617-a34f-e38d6fbe2c90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 583ms/step - accuracy: 0.7323 - loss: 0.5463 - val_accuracy: 0.7696 - val_loss: 0.4875\n",
            "Epoch 2/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 557ms/step - accuracy: 0.7779 - loss: 0.4721 - val_accuracy: 0.7900 - val_loss: 0.4525\n",
            "Epoch 3/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 557ms/step - accuracy: 0.8039 - loss: 0.4206 - val_accuracy: 0.8075 - val_loss: 0.4261\n",
            "Epoch 4/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 557ms/step - accuracy: 0.8194 - loss: 0.3962 - val_accuracy: 0.8248 - val_loss: 0.3933\n",
            "Epoch 5/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 557ms/step - accuracy: 0.8319 - loss: 0.3743 - val_accuracy: 0.8330 - val_loss: 0.3792\n",
            "Epoch 6/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 578ms/step - accuracy: 0.8404 - loss: 0.3570 - val_accuracy: 0.8356 - val_loss: 0.3722\n",
            "Epoch 7/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 577ms/step - accuracy: 0.8515 - loss: 0.3385 - val_accuracy: 0.8442 - val_loss: 0.3551\n",
            "Epoch 8/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 556ms/step - accuracy: 0.8572 - loss: 0.3277 - val_accuracy: 0.8461 - val_loss: 0.3536\n",
            "Epoch 9/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 556ms/step - accuracy: 0.8618 - loss: 0.3163 - val_accuracy: 0.8577 - val_loss: 0.3317\n",
            "Epoch 10/10\n",
            "\u001b[1m707/707\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 556ms/step - accuracy: 0.8698 - loss: 0.3011 - val_accuracy: 0.8619 - val_loss: 0.3222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance Visualization"
      ],
      "metadata": {
        "id": "GktAheNQXSFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to be continued ..."
      ],
      "metadata": {
        "id": "bX1iBH0xYRLy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-QgFgzdLYUIR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}